# Wildfire Detection Performance 20231018
## Training
Thanks to Mr. @Howie, we got 4 videos. And I randomly
picked 25 frames from 1st and 3rd video, separately to
enlarge the dataset we previously labeled on [Roboflow](https://app.roboflow.com/concordianavlab/avitags_navlab_20230930/2) as a new version (version2) dataset to train a YOLOv5l model.  
As we could seen, the following figures are the training
performance:
<figure class = "image">
    <img src="/figs/20231018/results.png"
     alt="All results"
     style="float: left; margin-right: 10px;" />
    <figcaption>{All results}</figcaption>
</figure>
<figure class = "image">
    <img src="/figs/20231018/PR_curve.png"
     alt="Precision-Recall Curve"     style="float: left; margin-right: 10px;" />
    <figcaption>{Precision-Recall Curve}</figcaption>
</figure>
<figure class = "image">
    <img src="/figs/20231018/F1_curve.png"
     alt="F1-Score Curve"     style="float: left; margin-right: 10px;" />
    <figcaption>{F1-Score Curve}</figcaption>
</figure>
<figure class = "image">
    <img src="/figs/20231018/labels_correlogram.jpg"
     alt="Label Distributions"     style="float: left; margin-right: 10px;" />
    <figcaption>{Label Distributions}</figcaption>
</figure>
  

## Testing
We use the 2nd and 4th video as the test data, to see the
trained model performance. As shown in the videos, the
performance is acceptable.  
However, what we need to take care during our deployment
is to set appropriate confidence. As shown in the
following figures, false alarms may appear if the
confidence is set too small, and the miss detection may
appear if the confidence is set too big. An appropriate
confidence will slightly sacrifice some edging detection
to ensure the entire performance.
<figure class = "image">
    <img src="/figs/20231018/yolov5l_v02.png"
     alt="YOLOv5l Performance on The 2nd Video"     style="float: left; margin-right: 10px;" />
    <figcaption>{YOLOv5l Performance on The 2nd Video}</figcaption>
</figure>
<figure class = "image">
    <img src="/figs/20231018/yolov5l_v04.png"
     alt="YOLOv5l Performance on The 4th Video"     style="float: left; margin-right: 10px;" />
    <figcaption>{YOLOv5l Performance on The 4th Video}</figcaption>
</figure>


## Continue Works
In this week, cooperating with @Qiaomeng Qin, we are
trying to update and deploy YOLOv8-based wildfire spot
bounding box coordinates output script (python script) to
our DJI M300 with ROS. Theoratically, If we convert it
into ROS node and make topic connections, this could be
deployed on both Icrest2.0 and the Gazebo simulator.  

If the detection model(s) could be converted into ROS
nodes, our goal of online wildfire spots detection and
geolocating will be achieved. For now, our solvement is
offline, which is to detect the wildfire spots, output
the wildfire-spot-bounding-box-coordinates, matching ORB
features in these bounding boxes, and then estimate the
distance and geolocate the wildfire spots.

For now, we are facing two issues:  
1. The YOLOv8 bug: The training does not work with my
   GT1660 GPU, and we tried to search and found it is
   caused by the model itself, many people are facing the
   same issue, and it could be solved by changing a nw or
   more powerful GPU. So we followed such steps and
   solved this issue yesterday.
2. The ROS we are using on Icrest seems not working well
   with our Python3 scripts, we can not import
   PyTorch successfully.  

Focusing on the 2nd issue, we are thinking some schemes:
* Try to find a python2-version PyTorch to see whether it
  could work;  
* Try to search if there is a way to call the python
  script through C++;
* Try to use ROS2 for Icrest(s).  

And we are working on it. I was wondering if you could
give us some advise if possible.

In the last experiment on 2023-10-13, we captured a video of wildfire
spot, but the flight height casued the wildfire spot
which could be seen in the video too small to be
labelled. So new experiment video could be helpful to
re-train the model to improve its online performance.
